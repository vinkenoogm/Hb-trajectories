{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotIndividuals(data, ids):\n",
    "    \"\"\"Plots the time series for a subset of donors, each donor gets their own plot.\n",
    "       In:  data: dataframe with donation data (with relative time)\n",
    "            ids : list of donor ids that should be plotted\n",
    "       Out: nothing, shows plots\"\"\"\n",
    "    \n",
    "    n = len(ids)\n",
    "    \n",
    "    a = np.floor(n**0.5).astype(int)\n",
    "    b = np.ceil(1.*n/a).astype(int)\n",
    "\n",
    "    fig = plt.figure(figsize=(5.*b, 3.*a))\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        s_id = ids[i-1]\n",
    "        df_sub = data.loc[data['KeyID'] == s_id, :]\n",
    "        ax = fig.add_subplot(a,b,i)\n",
    "        ax.plot(df_sub['TimeSinceFirst'], df_sub['Hb'])\n",
    "        for t in df_sub['TimeSinceFirst']:\n",
    "            ax.axvline(t, color='grey', lw=0.8)\n",
    "        ax.set_title('Donor ' + str(s_id))\n",
    "        ax.set_ylim(6, 12)\n",
    "        ax.set_xlabel('Days since first measurement')\n",
    "        ax.set_ylabel('Hb Value')\n",
    "        if s_id in id_f:\n",
    "            ax.axhline(y=7.8, color='red')\n",
    "        elif s_id in id_m:\n",
    "            ax.axhline(y=8.4, color='red')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(seq, target_length, padding=None):\n",
    "    length = len(seq)\n",
    "    seq.extend([padding] * (target_length - length))\n",
    "    return seq\n",
    "\n",
    "def makeSeriesDf(data, ids, interval, xmax):\n",
    "    \"\"\" Turns a long-format dataframe into one with subjects as rows and \n",
    "        measurements by time in the columns.\n",
    "        \n",
    "        Args:\n",
    "        data     : pandas dataframe in long-format\n",
    "        ids      : donors to be selected\n",
    "        interval : the desired interval to sample at (in days)\n",
    "        xmax     : the maximum time to be considered (in days)\n",
    "        \n",
    "        Returns:\n",
    "        y: dataframe with subjects as rows and measurements in columns\n",
    "    \"\"\"\n",
    "    y = pd.DataFrame(columns=list(range(0, xmax, interval)))\n",
    "    start = datetime.datetime.now()\n",
    "    counter = 0\n",
    "    \n",
    "    for d_id in ids:\n",
    "        df_sub = df.loc[df['KeyID'] == d_id, ['TimeSinceFirst', 'Hb']].dropna()\n",
    "        df_sub['TimeSinceFirst'] = pd.to_timedelta(df_sub['TimeSinceFirst'], unit='day')\n",
    "        df_sub = df_sub.resample('7d', on='TimeSinceFirst').mean().interpolate()\n",
    "        y.loc[d_id] = pad(list(df_sub['Hb']), y.shape[1])\n",
    "        \n",
    "        counter += 1\n",
    "        if counter in [10, 100, 1000, 10000] or (datetime.datetime.now() - start) / pd.Timedelta('1min') > 15:\n",
    "            print(datetime.datetime.now())\n",
    "            print(counter) \n",
    "            start = datetime.datetime.now()\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance measures\n",
    "# Adapted from http://alexminnaar.com/time-series-classification-and-clustering-with-python.html\n",
    "\n",
    "def DTWDistance(s1, s2, w):\n",
    "#     n = len(s1.dropna())\n",
    "#     m = len(s2.dropna())\n",
    "    DTW = {}\n",
    "    \n",
    "    n = min(len(s1.dropna()), len(s2.dropna()))\n",
    "    s1 = s1[:n]\n",
    "    s2 = s2[:n]\n",
    "\n",
    "#     w = max(w, abs(n - m))\n",
    "\n",
    "    for i in range(-1, n):\n",
    "        for j in range(-1, n):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(max(0, i-w), min(n, i+w)):\n",
    "            dist = (s1.iloc[i] - s2.iloc[j]) ** 2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)], DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return np.sqrt(DTW[n-1, n-1])\n",
    "\n",
    "def LB_Keogh(s1, s2, r):\n",
    "    LB_sum = 0\n",
    "    for index, value in enumerate(s1):\n",
    "        lower_bound = min(s2[(index-r if index-r >= 0 else 0):(index+r)])\n",
    "        upper_bound = max(s2[(index-r if index-r >= 0 else 0):(index+r)])\n",
    "\n",
    "        if value > upper_bound:\n",
    "            LB_sum = LB_sum + (value-upper_bound) ** 2\n",
    "        elif value < lower_bound:\n",
    "            LB_sum = LB_sum + (value-lower_bound) ** 2\n",
    "\n",
    "    return np.sqrt(LB_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "\n",
    "def k_means_clust(data, num_clust, num_iter, w=5, plot=False, ntry=0):\n",
    "    centroids = pd.DataFrame(np.random.uniform(low=5, high=12, size=(num_clust, len(data.columns))), \n",
    "                             index=list(range(0, num_clust)), \n",
    "                             columns=list(data.columns))\n",
    "    for n in range(num_iter):\n",
    "        print('Starting iteration', n+1)\n",
    "        print(datetime.datetime.now())\n",
    "        assignments = {k: [] for k in range(0, num_clust)} \n",
    "        \n",
    "        # Assign data points to clusters\n",
    "        for s_index, s_row in data.iterrows():\n",
    "            s_row = s_row.dropna()\n",
    "            min_dist = float('inf')\n",
    "            closest_clust = None\n",
    "            for c_index, c_row in centroids.iterrows():\n",
    "                c_row = c_row[:len(s_row)]\n",
    "                if LB_Keogh(s_row.squeeze(), c_row.squeeze(), w) < min_dist:\n",
    "                    cur_dist = DTWDistance(s_row.squeeze(), c_row, w)\n",
    "                    if cur_dist < min_dist:\n",
    "                        min_dist = cur_dist\n",
    "                        closest_clust = c_index\n",
    "            assignments[closest_clust].append(s_index)\n",
    "        \n",
    "        # If any clusters has zero data points, start over (max 3 times)\n",
    "        if any([is_empty(assignments[key]) for key in assignments.keys()]):\n",
    "            if ntry < 3:\n",
    "                print(\"Try\", ntry+1, \"failed, starting over\")\n",
    "                k_means_clust(data, num_clust, num_iter, w, plot, ntry+1)\n",
    "                break\n",
    "            else:\n",
    "                return(\"4 tries where a cluster got no data points\") \n",
    "            \n",
    "        # Recalculate centroids of clusters\n",
    "        for c_index in centroids.index:\n",
    "            s_rows = data.loc[data.index.isin(assignments[c_index])]           \n",
    "            centroids.loc[c_index] = s_rows.mean(axis=0).values  \n",
    "                \n",
    "    # After assigning all data points, calculate within-cluster distances\n",
    "    distances = pd.DataFrame(index=data.index, columns=['cluster', 'distance'])\n",
    "    for key in assignments.keys():\n",
    "        for s_index in assignments[key]:\n",
    "            s_row = data.loc[data.index == s_index].dropna(axis=1).squeeze()\n",
    "            c_row = centroids.loc[key][:len(s_row)].squeeze()\n",
    "            dist = DTWDistance(s_row, c_row, w)\n",
    "            distances.loc[distances.index == s_index, 'cluster'] = key\n",
    "            distances.loc[distances.index == s_index, 'distance'] = dist\n",
    "        \n",
    "    # Plot centroids\n",
    "    if plot:\n",
    "        for index, row in centroids.iterrows():\n",
    "            plt.plot(centroids.loc[index])\n",
    "        plt.show()\n",
    "    \n",
    "    return centroids, assignments, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeFeatures(df):\n",
    "    x = df.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_norm = pd.DataFrame(x_scaled, index=df.index, columns=df.columns)\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCentroids(df_features, df, k):\n",
    "    centroids = []\n",
    "    for num_clust in k:\n",
    "        kmeans = KMeans(n_clusters=num_clust)\n",
    "        kmeans.fit(df_features)\n",
    "        labels = kmeans.predict(df_features)\n",
    "        centroidsk = pd.DataFrame(0, index=list(range(0, num_clust)), columns=list(df.columns))\n",
    "\n",
    "        for c_index in range(0, num_clust):\n",
    "            df_cluster = df.loc[labels == c_index]\n",
    "            centroidsk.loc[c_index] = df_cluster.mean(axis=0).values\n",
    "\n",
    "        centroids.append(centroidsk)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateClusters(column, order):\n",
    "    return [order[x] for x in list(column)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
